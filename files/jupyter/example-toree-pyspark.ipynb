{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# **Python Example**\n",
    "\n",
    "This notebook will show you how to use **Apache Spark** with **Python** to perform a simple word count.\n",
    "\n",
    "You can run a cell by pressing **\"shift-enter\"**, which will compute the current cell and advance to the next cell, or by clicking in a cell and pressing **\"control-enter\"**, which will compute the current cell and remain in that cell.\n",
    "\n",
    "** This notebook covers: **\n",
    "* *Part 1:* Required Libraries\n",
    "* *Part 2:* Spark Context\n",
    "* *Part 3:* Word Count\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Import Required Libraries\n",
    "\n",
    "This section shows how to import python modules."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# If the SparkConf and SparkContext were required the following code cold be\n",
    "# used to import those features from pyspark:\n",
    "\n",
    "from pyspark import SparkConf\n",
    "from pyspark import SparkContext"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Spark Context\n",
    "\n",
    "Apache Toree creates a SparkContext when the kernel starts. You can access the context through the **sc** variable."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Word Count\n",
    "\n",
    "This section shows the Word Counter application."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load a text file\n",
    "text_file = sc.textFile(\"/srv/spark/LICENSE\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# count the times each word appears on the file\n",
    "counts = (text_file.flatMap(lambda line: line.split(' '))\n",
    "                   .map(lambda word: (word, 1))\n",
    "                   .reduceByKey(lambda a, b: a + b))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# top 15 words\n",
    "counts.takeOrdered(15, key=lambda x: -x[1])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*notebook writen by [fscm](https://github.com/fscm)*"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Toree - PySpark",
   "language": "python",
   "name": "toree_pyspark"
  },
  "language_info": {
   "file_extension": ".py",
   "name": "python",
   "pygments_lexer": "python",
   "version": "3.4.2\n"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
